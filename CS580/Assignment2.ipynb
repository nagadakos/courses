{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(fPath):\n",
    "    df = pd.read_csv(fPath, header = None, skipinitialspace = True)\n",
    "    # get classes to numpy array\n",
    "    data = df.iloc[:,:].to_numpy().copy()\n",
    "    \n",
    "    return data\n",
    "\n",
    "def count_values_from_frame(data):\n",
    "    # get columns of frame\n",
    "    columns = list(data)\n",
    "    featureCounts = dict()\n",
    "    # Count appearences of elements in all columns\n",
    "    for c in columns:\n",
    "        featureCounts[c] = df[c].value_counts()\n",
    "    #print(featureCounts)\n",
    "    return\n",
    "\n",
    "def count_features_per_class(data, normalize = True):\n",
    "    classes = np.unique(data[:,-1])\n",
    "    # Create a list of dictionaries, one for each feature. Each dictionary contains an entry for each unique feature value(key)\n",
    "    # and a list that contains the freq count for each class.\n",
    "    counterDict = []#[{} for x in range(data.shape[1]-1)]\n",
    "    #\n",
    "    classStats = np.zeros(len(classes))\n",
    "    for j, c in enumerate(classes):\n",
    "        for f in range(data.shape[1]-1):           \n",
    "            allKeys = np.unique(data[:,f])\n",
    "            #print(allKeys)\n",
    "            if len(counterDict) < f+1:\n",
    "                counterDict.append(dict( (a, [0 for c in range(0, len(classes))]) for a in allKeys))\n",
    "            \n",
    "            keys, freqs = (np.unique(data[[data[:,-1] == c]][:,f], return_counts = True))\n",
    "            for i,k in enumerate(keys):\n",
    "                counterDict[f][k][j] = freqs[i] \n",
    "        # Compute per class frequencies, for comptueting info gain\n",
    "        for f in range(data.shape[0]):\n",
    "            if data[f,-1] == c:\n",
    "                classStats[j] += 1\n",
    "   \n",
    "    return counterDict, classStats/data.shape[0]\n",
    "    \n",
    "def comp_feat_entropy(dataDicts, epsilon = 0.001, debug = False):\n",
    "    \"\"\"\n",
    "        ARGUMENTS: dataDict (list of dicts): A list holding one dictionary per feature (attribute). Each discionary holds an entry with a key for each unique variable.\n",
    "                                             Each variable's (key's) value is a list containing the accurencies each variable appears in each class. So the struct\n",
    "                   epsilon (float):          float guarding against log(0) \n",
    "    \"\"\"\n",
    "    total = 0\n",
    "    #print(dataDict[0])\n",
    "    if type(dataDicts) is not list:\n",
    "        dataDicts = [dataDicts]\n",
    "    # Iterate over features\n",
    "    featEntropy = []\n",
    "    for i, feature in enumerate(dataDicts):\n",
    "        if debug: print(feature)\n",
    "        a = np.array([feature[k] for k in feature.keys()])\n",
    "        total += np.sum(a)\n",
    "        if debug: print(a, a.sum())\n",
    "        # Compute the percantage of the population each value represents. i.e if a appears in half the samples then a_frac=0.5\n",
    "        featFracs  = [np.sum(f)/total for f in a]\n",
    "        # Compute the percentage that each value appears in each class. i.e if a is 25% in class 1 and 75% in class 2, then a_classFracs = [0.25, 0.75]\n",
    "        classFracs = np.array([f/np.sum(f) for f in a])\n",
    "        # Compute class entropy if wfor spliting on each appearring value. Epsilon guards against the log2(0) case\n",
    "        classEntropy = np.array([-np.sum(((f[:]+epsilon) * np.log2(f[:]+epsilon))) for f in classFracs])\n",
    "        # Compute resulting conditional class entropy for this feature H(S|a) by taking the expectation over all Entropy for all apeparing values.\n",
    "        featEntropy.append(np.sum(featFracs * classEntropy))\n",
    "        total = 0\n",
    "        if debug: \n",
    "            print(featFracs)\n",
    "            print(classFracs)\n",
    "            print(classEntropy)\n",
    "            print(featEntropy)\n",
    "    return np.array(featEntropy)\n",
    "        \n",
    "def compute_feat_info_gain(dataDict, classDist, epsilon = 0.0001, debug = False):\n",
    "    # Compute all conditional Entropies for all features\n",
    "    featEntropy = comp_feat_entropy(dataDict)    \n",
    "    # Compute aggregate class entropy before any featue split\n",
    "    classEntropy = -np.sum((classDist[:]) * np.log2(classDist[:]))\n",
    "    # Compute Information gain I(S;A) for all attributes A\n",
    "    infoGain = classEntropy - featEntropy\n",
    "    if debug: print(infoGain)\n",
    "    return infoGain\n",
    "    \n",
    "def compute_attribure_entropy():\n",
    "    a =0 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 6)\n",
      "[['young' 'FALSE' 'FALSE' 'fair' 'x' 'No']\n",
      " ['young' 'FALSE' 'FALSE' 'good' 'x' 'Mix']\n",
      " ['young' 'TRUE' 'SURE' 'good' 'x' 'Yes']\n",
      " ['young' 'TRUE' 'TRUE' 'fair' 'y' 'Yes']\n",
      " ['young' 'Maybe' 'FALSE' 'fair' 'x' 'No']\n",
      " ['middle' 'FALSE' 'FALSE' 'fair' 'x' 'Mix']\n",
      " ['middle' 'FALSE' 'FALSE' 'good' 'y' 'No']\n",
      " ['middle' 'TRUE' 'TRUE' 'good' 'z' 'Yes']\n",
      " ['middle' 'FALSE' 'SURE' 'excellent' 'y' 'Yes']\n",
      " ['middle' 'FALSE' 'TRUE' 'excellent' 'y' 'Mix']\n",
      " ['old' 'Maybe' 'TRUE' 'excellent' 'y' 'Yes']\n",
      " ['old' 'FALSE' 'TRUE' 'good' 'x' 'Mix']\n",
      " ['old' 'TRUE' 'FALSE' 'good' 'z' 'Yes']\n",
      " ['old' 'TRUE' 'FALSE' 'excellent' 'x' 'Mix']\n",
      " ['old' 'Maybe' 'FALSE' 'fair' 'y' 'No']\n",
      " ['teenager' 'TRUE' 'TRUE' 'good' 'x' 'Mix']\n",
      " ['teenager' 'FALSE' 'SURE' 'good' 'y' 'No']\n",
      " ['teenager' 'TRUE' 'TRUE' 'excellent' 'z' 'Yes']\n",
      " ['teenager' 'Maybe' 'TRUE' 'excellent' 'x' 'Mix']\n",
      " ['teenager' 'TRUE' 'FALSE' 'excellent' 'z' 'Yes']]\n",
      "[['young' 'TRUE' 'SURE' 'good' 'x' 'Yes']\n",
      " ['young' 'TRUE' 'TRUE' 'fair' 'y' 'Yes']\n",
      " ['middle' 'TRUE' 'TRUE' 'good' 'z' 'Yes']\n",
      " ['middle' 'FALSE' 'SURE' 'excellent' 'y' 'Yes']\n",
      " ['old' 'Maybe' 'TRUE' 'excellent' 'y' 'Yes']\n",
      " ['old' 'TRUE' 'FALSE' 'good' 'z' 'Yes']\n",
      " ['teenager' 'TRUE' 'TRUE' 'excellent' 'z' 'Yes']\n",
      " ['teenager' 'TRUE' 'FALSE' 'excellent' 'z' 'Yes']]\n"
     ]
    }
   ],
   "source": [
    "fPath = \"B:/Workspaces/courses/CS580/assignments-1-2-3-testData/assign-2-testData/2-data-1.txt\"#\"dummy2.txt\"\n",
    "data = load_data(fPath)\n",
    "print(data.shape)\n",
    "print(data)\n",
    "print(data[data[:,-1] == 'Yes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-132-3087fa5be460>:32: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  keys, freqs = (np.unique(data[[data[:,-1] == c]][:,f], return_counts = True))\n"
     ]
    }
   ],
   "source": [
    "dataDict, classDist = count_features_per_class(data)\n",
    "#print(dataDict, classDist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'FALSE': [3, 4, 2], 'SURE': [0, 1, 2], 'TRUE': [4, 0, 4]}\n",
      "[[3 4 2]\n",
      " [0 1 2]\n",
      " [4 0 4]] 20\n",
      "[0.45, 0.15, 0.4]\n",
      "[[0.33333333 0.44444444 0.22222222]\n",
      " [0.         0.33333333 0.66666667]\n",
      " [0.5        0.         0.5       ]]\n",
      "[1.53108276 0.92754291 1.00907751]\n",
      "[1.231749682433986]\n",
      "Resulting Entropy is:  [1.23174968]\n"
     ]
    }
   ],
   "source": [
    "# Proof of concept debug\n",
    "featEntropy = comp_feat_entropy(dataDict[2], debug = True)\n",
    "print(\"Resulting Entropy is: \", featEntropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.03631326 0.36774426 0.32712217 0.24314639 0.4960771 ]\n",
      "[0 3 2 1 4] [0.03631326 0.36774426 0.32712217 0.24314639 0.4960771 ]\n",
      "Most Informative feature:  4  with Info gain:  0.4960770969973616\n",
      "Complete order:\n",
      "Feature 4, Info Gain: 0.4960770969973616\n",
      "Feature 1, Info Gain: 0.36774426292708107\n",
      "Feature 2, Info Gain: 0.3271221660113741\n",
      "Feature 3, Info Gain: 0.2431463938840257\n",
      "Feature 0, Info Gain: 0.03631325887309744\n"
     ]
    }
   ],
   "source": [
    "featureInfoGain = compute_feat_info_gain(dataDict, classDist)\n",
    "print(featureInfoGain)\n",
    "order = np.argsort(featureInfoGain)\n",
    "print(order, featureInfoGain)\n",
    "print(\"Most Informative feature: \", order[-1], \" with Info gain: \", featureInfoGain[order[-1]])\n",
    "print(\"Complete order:\",*[\"Feature {}, Info Gain: {}\".format(i, featureInfoGain[i]) for i in order[::-1]],sep = '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_to_str(featureInfoGain, order, sId = 'nagada2'):\n",
    "    ''' DESCRIPTION: Format return string\n",
    "    '''\n",
    "    retStr = ''.join(('(', sId,'\\n', *['Feature: {}, Info Gain: {}\\n'.format(i, featureInfoGain[i]) for i in order[::-1]], ')'))\n",
    "    return retStr\n",
    "\n",
    "def demo_result_to_str(featureInfoGain, order, sId = 'nagada2'):\n",
    "    ''' DESCRIPTION: Format return string\n",
    "    '''\n",
    "    retStr = ''.join(('(', sId,'\\n', '(IG ', str(featureInfoGain [0]),')\\n)'))\n",
    "    return retStr\n",
    "\n",
    "def write_string_to_file(s, wFile = 'results2.txt'):\n",
    "    ''' DESCRIPTION: Write string to target file.\n",
    "    '''\n",
    "    try:\n",
    "        with open(wFile, 'w') as wf:\n",
    "            wf.write(s)\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete order:\n",
      "(54\n",
      "(IG 0.03631325887309744)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "sId = '54'\n",
    "retStr = demo_result_to_str(featureInfoGain, order, sId)\n",
    "saveFile = '_'.join((sId, '2.txt'))\n",
    "write_string_to_file(retStr, wFile = saveFile)\n",
    "print(\"Complete order:\", retStr, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
